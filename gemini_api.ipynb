{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Gemini API: Interactive Lab\n",
    "<a href=\"https://colab.research.google.com/github/IAT-ComputationalCreativity-Spring2025/Week10-APIs/blob/main/gemini_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "In this lab, we'll explore the basic usage of LLM APIs using Gemini's limited free tier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting a key\n",
    "\n",
    "If you haven't already, go to https://aistudio.google.com/apikeyâ€‹ to sign in and create a new api key\n",
    "\n",
    "Make sure not to share this key publicly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# This will prompt for your API key but won't display what you type\n",
    "from getpass import getpass\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['GEMINI_API_KEY'] = getpass('Enter your Gemini API key: ')\n",
    "\n",
    "# Verify keys are set (without revealing them)\n",
    "print(f\"Gemini API key is set: {'Yes' if 'GEMINI_API_KEY' in os.environ else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Gemini API\n",
    "! pip install google-generativeai\n",
    "# OpenAI API (optional)\n",
    "#! pip install openai\n",
    "# Stability AI (optional)\n",
    "#! pip install stability-sdk\n",
    "\n",
    "# For interactive widgets in Jupyter\n",
    "! pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: API Configuration Module\n",
    "\n",
    "Let's create a helper module to manage API access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to get keys from multiple sources in order of security preference\n",
    "def get_api_key(service):\n",
    "    \"\"\"Get API key from various sources in order of security preference\"\"\"\n",
    "    if service.lower() == \"gemini\":\n",
    "        key = os.environ.get('GEMINI_API_KEY')\n",
    "\n",
    "        if key and key != \"your_gemini_api_key_here\":\n",
    "            return key\n",
    "            \n",
    "        # No key found\n",
    "        raise ValueError(f\"No API key found for {service}. Please set up your API key using one of the methods in the notebook.\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported service: {service}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Testing API Connection\n",
    "\n",
    "Let's test our API connection using the Gemini API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the current directory to path if needed\n",
    "sys.path.append(os.path.abspath(\"\"))\n",
    "\n",
    "# Test Gemini API\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Configure the API\n",
    "    api_key = get_api_key(\"gemini\")\n",
    "    genai.configure(api_key=api_key)\n",
    "\n",
    "    # Test a simple query\n",
    "    model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "    response = model.generate_content(\"Write a haiku about artificial intelligence\")\n",
    "\n",
    "    print(\"API Connection Successful!\")\n",
    "    print(\"\\nHaiku response:\")\n",
    "    print(response.text)\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to API: {e}\")\n",
    "    print(\"\\nPlease check your API key configuration and try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: API Rate Limit Monitoring and Error Handling\n",
    "\n",
    "Create utility functions for API rate limiting and error handling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "from functools import wraps\n",
    "\n",
    "class APIRateLimiter:\n",
    "    def __init__(self, service_name, requests_per_minute=60):\n",
    "        self.service_name = service_name\n",
    "        self.min_interval = 60 / requests_per_minute  # seconds between requests\n",
    "        self.last_request_time = 0\n",
    "        self.request_count = 0\n",
    "        \n",
    "    def request(self, func):\n",
    "        \"\"\"Decorator to manage API request rates\"\"\"\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            # Check if we need to wait\n",
    "            current_time = time.time()\n",
    "            elapsed = current_time - self.last_request_time\n",
    "            \n",
    "            if elapsed < self.min_interval:\n",
    "                wait_time = self.min_interval - elapsed\n",
    "                print(f\"Rate limiting: waiting {wait_time:.2f} seconds...\")\n",
    "                time.sleep(wait_time)\n",
    "            \n",
    "            # Make the request\n",
    "            self.request_count += 1\n",
    "            self.last_request_time = time.time()\n",
    "            print(f\"Making request #{self.request_count} to {self.service_name}\")\n",
    "            \n",
    "            return func(*args, **kwargs)\n",
    "        return wrapper\n",
    "\n",
    "\n",
    "def retry_with_exponential_backoff(initial_delay=1, max_delay=60, max_retries=5):\n",
    "    \"\"\"Retry decorator with exponential backoff\"\"\"\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            delay = initial_delay\n",
    "            retries = 0\n",
    "            \n",
    "            while retries < max_retries:\n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "                except Exception as e:\n",
    "                    print(f\"Request failed: {e}\")\n",
    "                    retries += 1\n",
    "                    \n",
    "                    if retries >= max_retries:\n",
    "                        print(f\"Maximum retries ({max_retries}) exceeded.\")\n",
    "                        raise\n",
    "                    \n",
    "                    sleep_time = min(delay * (2 ** (retries - 1)) + random.uniform(0, 1), max_delay)\n",
    "                    print(f\"Retrying in {sleep_time:.2f} seconds... (Attempt {retries+1}/{max_retries})\")\n",
    "                    time.sleep(sleep_time)\n",
    "            \n",
    "            return func(*args, **kwargs)  # One last try\n",
    "        return wrapper\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our rate limiter and retry logic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rate limiters\n",
    "gemini_limiter = APIRateLimiter(\"Gemini\", requests_per_minute=60)\n",
    "\n",
    "@gemini_limiter.request\n",
    "def generate_with_gemini(prompt):\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "# Test with a few requests\n",
    "topics = [\"water\", \"air\", \"fire\"]\n",
    "for i in range(min(3, len(topics))):\n",
    "    try:\n",
    "        result = generate_with_gemini(f\"Give me one idea for a science project about {topics[i]}\")\n",
    "        print(f\"Result: {result[:100]}...\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test retry logic with an intentionally challenging request\n",
    "@retry_with_exponential_backoff(max_retries=3)\n",
    "def robust_generate_with_gemini(prompt):\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "try:\n",
    "    very_long_prompt = \"Explain quantum computing \" * 20\n",
    "    result = robust_generate_with_gemini(very_long_prompt)\n",
    "    print(f\"\\nSuccess! First 100 chars: {result[:100]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"Final failure: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Creating a Comprehensive Helper Class\n",
    "\n",
    "Let's create a comprehensive AI client class for our lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIClient:\n",
    "    \"\"\"A unified client for interacting with generative AI APIs\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.services = {}\n",
    "        self.request_logs = []\n",
    "        \n",
    "        # Initialize available services\n",
    "        self._init_gemini()\n",
    "    \n",
    "    def _init_gemini(self):\n",
    "        \"\"\"Initialize Gemini API if key is available\"\"\"\n",
    "        try:\n",
    "            api_key = get_api_key(\"gemini\")\n",
    "            if api_key:\n",
    "                genai.configure(api_key=api_key)\n",
    "                self.services[\"gemini\"] = {\n",
    "                    \"text_model\": genai.GenerativeModel('gemini-2.0-flash'),\n",
    "                    \"rate_limit\": 60,  # requests per minute\n",
    "                    \"last_request\": 0,\n",
    "                }\n",
    "                print(\"Gemini API initialized successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not initialize Gemini API: {e}\")\n",
    "    \n",
    "    def _rate_limit(self, service):\n",
    "        \"\"\"Apply rate limiting for the specified service\"\"\"\n",
    "        if service not in self.services:\n",
    "            raise ValueError(f\"Service {service} not initialized\")\n",
    "        \n",
    "        min_interval = 60 / self.services[service][\"rate_limit\"]\n",
    "        current_time = time.time()\n",
    "        elapsed = current_time - self.services[service][\"last_request\"]\n",
    "        \n",
    "        if elapsed < min_interval:\n",
    "            wait_time = min_interval - elapsed\n",
    "            print(f\"Rate limiting {service}: waiting {wait_time:.2f} seconds...\")\n",
    "            time.sleep(wait_time)\n",
    "        \n",
    "        self.services[service][\"last_request\"] = time.time()\n",
    "    \n",
    "    def generate_text(self, prompt, service=\"gemini\", max_retries=3):\n",
    "        \"\"\"Generate text from a text prompt using the specified service\"\"\"\n",
    "        if service not in self.services:\n",
    "            raise ValueError(f\"Service {service} not available\")\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                self._rate_limit(service)\n",
    "                \n",
    "                if service == \"gemini\":\n",
    "                    response = self.services[service][\"text_model\"].generate_content(prompt)\n",
    "                    \n",
    "                    # Log the request\n",
    "                    self.request_logs.append({\n",
    "                        \"service\": service,\n",
    "                        \"prompt\": prompt[:100] + \"...\" if len(prompt) > 100 else prompt,\n",
    "                        \"timestamp\": time.time(),\n",
    "                        \"success\": True\n",
    "                    })\n",
    "                    \n",
    "                    return response.text\n",
    "                else:\n",
    "                    raise NotImplementedError(f\"Text generation not implemented for {service}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error ({attempt+1}/{max_retries}): {e}\")\n",
    "                if attempt == max_retries - 1:\n",
    "                    # Log the failed request\n",
    "                    self.request_logs.append({\n",
    "                        \"service\": service,\n",
    "                        \"prompt\": prompt[:100] + \"...\" if len(prompt) > 100 else prompt,\n",
    "                        \"timestamp\": time.time(),\n",
    "                        \"success\": False,\n",
    "                        \"error\": str(e)\n",
    "                    })\n",
    "                    raise\n",
    "                time.sleep(2 ** attempt)  # Exponential backoff\n",
    "    \n",
    "    def get_usage_stats(self):\n",
    "        \"\"\"Return usage statistics for all services\"\"\"\n",
    "        stats = {}\n",
    "        for service in self.services:\n",
    "            service_logs = [log for log in self.request_logs if log[\"service\"] == service]\n",
    "            stats[service] = {\n",
    "                \"total_requests\": len(service_logs),\n",
    "                \"successful_requests\": len([log for log in service_logs if log[\"success\"]]),\n",
    "                \"failed_requests\": len([log for log in service_logs if not log[\"success\"]]),\n",
    "            }\n",
    "        return stats\n",
    "    \n",
    "    def compare_responses(self, prompt, services=None):\n",
    "        \"\"\"Compare responses from multiple services\"\"\"\n",
    "        if services is None:\n",
    "            services = list(self.services.keys())\n",
    "        \n",
    "        results = {}\n",
    "        for service in services:\n",
    "            try:\n",
    "                results[service] = self.generate_text(prompt, service=service)\n",
    "            except Exception as e:\n",
    "                results[service] = f\"Error: {e}\"\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our AIClient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the client\n",
    "client = AIClient()\n",
    "\n",
    "# Use the client\n",
    "try:\n",
    "    response = client.generate_text(\"Explain the concept of API rate limiting in three sentences\")\n",
    "    print(response)\n",
    "\n",
    "    # Check usage\n",
    "    print(\"\\nUsage Statistics:\")\n",
    "    print(client.get_usage_stats())\n",
    "except Exception as e:\n",
    "    print(f\"Error using AIClient: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: An example use case -- ScientificArticleSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "import ipywidgets as widgets\n",
    "import time\n",
    "import json\n",
    "\n",
    "class ScientificArticleSummarizer:\n",
    "    def __init__(self):\n",
    "        self.history = []  # Store previous summaries\n",
    "        \n",
    "    def summarize_article(self, article_text, audience_level=\"general\", focus_areas=None, max_length=500):\n",
    "        \"\"\"\n",
    "        Summarizes scientific article for different audience levels with specified focus\n",
    "        \n",
    "        Parameters:\n",
    "        - article_text (str): The text of the article to summarize\n",
    "        - audience_level (str): \"general\", \"undergraduate\", \"graduate\", or \"expert\"\n",
    "        - focus_areas (list): Specific aspects to focus on (e.g. [\"methodology\", \"results\"])\n",
    "        - max_length (int): Maximum length of summary in words\n",
    "        \n",
    "        Returns:\n",
    "        - str: The generated summary\n",
    "        \"\"\"\n",
    "\n",
    "        # Set default focus areas if none provided\n",
    "        if focus_areas is None:\n",
    "            focus_areas = [\"main findings\", \"methodology\", \"significance\"]\n",
    "        \n",
    "        # Determine language style based on audience level\n",
    "        language_style = {\n",
    "            \"general\": \"simple language avoiding technical jargon\",\n",
    "            \"undergraduate\": \"introductory academic language with basic field-specific terms\",\n",
    "            \"graduate\": \"advanced academic language with field-specific terminology\",\n",
    "            \"expert\": \"specialized technical language appropriate for experts in the field\"\n",
    "        }.get(audience_level, \"clear and concise language\")\n",
    "        \n",
    "        # Build the prompt\n",
    "        prompt = f\"\"\"\n",
    "        Please summarize the following scientific article for a {audience_level} audience.\n",
    "        Use {language_style}.\n",
    "        \n",
    "        Focus specifically on: {\", \".join(focus_areas)}.\n",
    "        Keep the summary under {max_length} words.\n",
    "        \n",
    "        Structure your response with clear sections and bullet points where appropriate.\n",
    "        \n",
    "        Article:\n",
    "        {article_text[:5000]}...\n",
    "        \"\"\"\n",
    "        \n",
    "        if len(article_text) > 5000:\n",
    "            prompt += \"\\n[Note: Article text was truncated due to length. This summary is based on the first portion of the article.]\"\n",
    "        \n",
    "        # Generate the summary\n",
    "        try:\n",
    "            summary = client.generate_text(prompt)\n",
    "            \n",
    "            # Add to history\n",
    "            self.history.append({\n",
    "                \"timestamp\": time.time(),\n",
    "                \"audience_level\": audience_level,\n",
    "                \"focus_areas\": focus_areas,\n",
    "                \"summary_length\": len(summary.split()),\n",
    "                \"summary\": summary\n",
    "            })\n",
    "            \n",
    "            return summary\n",
    "        except Exception as e:\n",
    "            return f\"Error generating summary: {str(e)}\"\n",
    "    \n",
    "    def extract_key_elements(self, article_text):\n",
    "        \"\"\"\n",
    "        Extracts key elements from the article such as:\n",
    "        - Main findings\n",
    "        - Methodology\n",
    "        - Limitations\n",
    "        - Future research directions\n",
    "        - Practical implications\n",
    "        \n",
    "        Returns a structured dictionary of these elements\n",
    "        \"\"\"\n",
    "        \n",
    "        prompt = \"\"\"\n",
    "        Analyze the following scientific article and extract these key elements:\n",
    "        1. Main Findings: The primary results or discoveries reported\n",
    "        2. Methodology: The research approach, methods, and techniques used\n",
    "        3. Limitations: Any constraints, weaknesses, or limitations acknowledged\n",
    "        4. Future Research: Suggested directions for further study\n",
    "        5. Practical Implications: Real-world applications or consequences\n",
    "        \n",
    "        Format your response as a structured JSON object with these elements as keys.\n",
    "        Keep each element concise (2-3 sentences).\n",
    "        \n",
    "        Article:\n",
    "        \"\"\" + article_text[:5000]\n",
    "\n",
    "        try:\n",
    "            response = client.generate_text(prompt)\n",
    "            \n",
    "            # Try to parse the response as JSON\n",
    "            # If it's not perfectly formatted JSON, we'll need to extract it\n",
    "            try:\n",
    "                # Look for a JSON block in the response\n",
    "                import re\n",
    "                json_match = re.search(r'```json\\s*([\\s\\S]*?)\\s*```', response)\n",
    "                if json_match:\n",
    "                    json_str = json_match.group(1)\n",
    "                else:\n",
    "                    json_str = response\n",
    "                \n",
    "                # Clean up and parse\n",
    "                return json.loads(json_str)\n",
    "            except json.JSONDecodeError:\n",
    "                # If parsing fails, return the raw response\n",
    "                return {\"error\": \"Could not parse structured data\", \"raw_response\": response}\n",
    "                \n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Error extracting key elements: {str(e)}\"}\n",
    "    \n",
    "    def generate_follow_up_questions(self, article_text, num_questions=5):\n",
    "        \"\"\"\n",
    "        Generates follow-up questions that might be asked after reading the article\n",
    "        \"\"\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        Based on the following scientific article, generate {num_questions} thoughtful follow-up questions that:\n",
    "        1. Probe deeper into the methodology or findings\n",
    "        2. Address potential limitations or gaps\n",
    "        3. Explore implications or applications of the research\n",
    "        4. Connect this research to broader scientific contexts\n",
    "        5. Suggest future research directions\n",
    "        \n",
    "        Format each question as a separate numbered point.\n",
    "        \n",
    "        Article:\n",
    "        {article_text[:5000]}\n",
    "        \"\"\"\n",
    "        \n",
    "        return client.generate_text(prompt)\n",
    "            \n",
    "    def compare_prompt_techniques(self, article_text, techniques=None):\n",
    "        \"\"\"\n",
    "        Compares different prompt engineering techniques on the same article\n",
    "        Returns a dictionary with results from each technique\n",
    "        \"\"\"\n",
    "        if techniques is None:\n",
    "            techniques = {\n",
    "                \"Basic\": \"Summarize this scientific article\",\n",
    "                \"Specific\": \"Summarize this scientific article, focusing on the methodology and findings\",\n",
    "                \"Role-based\": \"You are a scientific research assistant helping a professor. Summarize this article highlighting key contributions\",\n",
    "                \"Step-by-step\": \"First, identify the research question. Second, describe the methodology. Third, explain the results. Finally, summarize the conclusions.\",\n",
    "                \"Few-shot\": \"Example summary 1: [Paper title] investigated [topic] using [method] and found [result].\\nExample summary 2: The researchers explored [topic] through [method], revealing [result].\\nNow summarize this article in a similar style:\"\n",
    "            }\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        for name, prompt_template in techniques.items():\n",
    "            full_prompt = f\"{prompt_template}\\n\\nArticle:\\n{article_text[:3000]}\"\n",
    "            \n",
    "            try:\n",
    "                results[name] = client.generate_text(full_prompt)\n",
    "            except Exception as e:\n",
    "                results[name] = f\"Error: {str(e)}\"\n",
    "                \n",
    "        return results\n",
    "    \n",
    "    def get_citation_recommendation(self, article_text):\n",
    "        \"\"\"Recommends how to cite this article based on its content\"\"\"\n",
    "        \n",
    "        prompt = \"\"\"\n",
    "        Based on the content of this scientific article, generate:\n",
    "        1. An APA style citation (assume current year if publication date isn't mentioned)\n",
    "        2. Three key points that would be most relevant to cite from this paper\n",
    "        3. Potential fields or topics where citing this article would be appropriate\n",
    "        \n",
    "        Article:\n",
    "        \"\"\" + article_text[:4000]\n",
    "        \n",
    "        return client.generate_text(prompt)\n",
    "    \n",
    "    def summarize_with_visuals(self, article_text):\n",
    "        \"\"\"\n",
    "        Provides guidance on what visual elements would complement a summary\n",
    "        of this article (diagrams, charts, etc.)\n",
    "        \"\"\"\n",
    "        \n",
    "        prompt = \"\"\"\n",
    "        Based on this scientific article, recommend 3-5 visual elements (diagrams, \n",
    "        charts, figures) that would best complement a summary of this research.\n",
    "        \n",
    "        For each recommended visual:\n",
    "        1. Describe what the visual should show\n",
    "        2. Explain why this visualization would be valuable\n",
    "        3. Suggest a title and caption\n",
    "        \n",
    "        Article:\n",
    "        \"\"\" + article_text[:4000]\n",
    "        \n",
    "        return client.generate_text(prompt)\n",
    "\n",
    "# Create a simple demo UI with widgets\n",
    "def create_summarizer_ui():\n",
    "    \"\"\"Creates an interactive UI for the scientific article summarizer\"\"\"\n",
    "    # Create the summarizer\n",
    "    summarizer = ScientificArticleSummarizer()\n",
    "    \n",
    "    # Create widgets\n",
    "    article_input = widgets.Textarea(\n",
    "        value='',\n",
    "        placeholder='Paste scientific article text here',\n",
    "        description='Article:',\n",
    "        layout={'width': '100%', 'height': '200px'}\n",
    "    )\n",
    "    \n",
    "    audience_dropdown = widgets.Dropdown(\n",
    "        options=['general', 'undergraduate', 'graduate', 'expert'],\n",
    "        value='undergraduate',\n",
    "        description='Audience:',\n",
    "        layout={'width': '50%'}\n",
    "    )\n",
    "    \n",
    "    focus_checkboxes = widgets.SelectMultiple(\n",
    "        options=['main findings', 'methodology', 'significance', 'limitations', 'future research', 'practical implications'],\n",
    "        value=['main findings', 'methodology', 'significance'],\n",
    "        description='Focus on:',\n",
    "        layout={'width': '50%'}\n",
    "    )\n",
    "    \n",
    "    max_length_slider = widgets.IntSlider(\n",
    "        value=500,\n",
    "        min=100,\n",
    "        max=1000,\n",
    "        step=50,\n",
    "        description='Max length:',\n",
    "        layout={'width': '50%'}\n",
    "    )\n",
    "    \n",
    "    summarize_button = widgets.Button(\n",
    "        description='Summarize Article',\n",
    "        button_style='primary',\n",
    "        icon='file-text'\n",
    "    )\n",
    "    \n",
    "    extract_button = widgets.Button(\n",
    "        description='Extract Key Elements',\n",
    "        button_style='info',\n",
    "        icon='list'\n",
    "    )\n",
    "    \n",
    "    questions_button = widgets.Button(\n",
    "        description='Generate Questions',\n",
    "        button_style='success',\n",
    "        icon='question'\n",
    "    )\n",
    "    \n",
    "    compare_button = widgets.Button(\n",
    "        description='Compare Prompt Techniques',\n",
    "        button_style='warning',\n",
    "        icon='random'\n",
    "    )\n",
    "    \n",
    "    output_area = widgets.Output(\n",
    "        layout={'border': '1px solid #ddd', 'min_height': '200px', 'width': '100%', 'padding': '10px'}\n",
    "    )\n",
    "    \n",
    "    # Define button actions\n",
    "    def on_summarize_clicked(b):\n",
    "        with output_area:\n",
    "            output_area.clear_output()\n",
    "            print(\"Generating summary...\")\n",
    "            summary = summarizer.summarize_article(\n",
    "                article_input.value,\n",
    "                audience_level=audience_dropdown.value,\n",
    "                focus_areas=list(focus_checkboxes.value),\n",
    "                max_length=max_length_slider.value\n",
    "            )\n",
    "            output_area.clear_output()\n",
    "            display(Markdown(summary))\n",
    "    \n",
    "    def on_extract_clicked(b):\n",
    "        with output_area:\n",
    "            output_area.clear_output()\n",
    "            print(\"Extracting key elements...\")\n",
    "            elements = summarizer.extract_key_elements(article_input.value)\n",
    "            output_area.clear_output()\n",
    "            \n",
    "            if isinstance(elements, dict) and \"error\" not in elements:\n",
    "                for key, value in elements.items():\n",
    "                    display(Markdown(f\"**{key}**: {value}\"))\n",
    "            else:\n",
    "                print(elements)\n",
    "    \n",
    "    def on_questions_clicked(b):\n",
    "        with output_area:\n",
    "            output_area.clear_output()\n",
    "            print(\"Generating follow-up questions...\")\n",
    "            questions = summarizer.generate_follow_up_questions(article_input.value)\n",
    "            output_area.clear_output()\n",
    "            \n",
    "            if isinstance(questions, list):\n",
    "                for i, question in enumerate(questions, 1):\n",
    "                    display(Markdown(f\"{i}. {question}\"))\n",
    "            else:\n",
    "                display(Markdown(questions))\n",
    "    \n",
    "    def on_compare_clicked(b):\n",
    "        with output_area:\n",
    "            output_area.clear_output()\n",
    "            print(\"Comparing prompt techniques...\")\n",
    "            results = summarizer.compare_prompt_techniques(article_input.value)\n",
    "            output_area.clear_output()\n",
    "            \n",
    "            for technique, result in results.items():\n",
    "                display(Markdown(f\"### Technique: {technique}\"))\n",
    "                display(Markdown(result))\n",
    "                display(Markdown(\"---\"))\n",
    "    \n",
    "    # Connect buttons to actions\n",
    "    summarize_button.on_click(on_summarize_clicked)\n",
    "    extract_button.on_click(on_extract_clicked)\n",
    "    questions_button.on_click(on_questions_clicked)\n",
    "    compare_button.on_click(on_compare_clicked)\n",
    "    \n",
    "    # Create tabs for different functionalities\n",
    "    tab_summarize = widgets.VBox([\n",
    "        widgets.HBox([audience_dropdown, max_length_slider]),\n",
    "        focus_checkboxes,\n",
    "        summarize_button\n",
    "    ])\n",
    "    \n",
    "    tab_analyze = widgets.VBox([\n",
    "        extract_button,\n",
    "        questions_button,\n",
    "        compare_button\n",
    "    ])\n",
    "    \n",
    "    tabs = widgets.Tab(children=[tab_summarize, tab_analyze])\n",
    "    tabs.set_title(0, 'Summarize')\n",
    "    tabs.set_title(1, 'Analyze')\n",
    "    \n",
    "    # Assemble the complete UI\n",
    "    ui = widgets.VBox([\n",
    "        widgets.HTML(\"<h2>Scientific Article Summarizer</h2>\"),\n",
    "        article_input,\n",
    "        tabs,\n",
    "        widgets.HTML(\"<h3>Output:</h3>\"),\n",
    "        output_area\n",
    "    ])\n",
    "    \n",
    "    return ui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Try it!\n",
    "\n",
    "Copy in the text from a scientific article (or just generate one below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.generate_text(\"Make up a short scientific paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run the interactive UI in a notebook:\n",
    "from IPython.display import display\n",
    "\n",
    "ui = create_summarizer_ui()\n",
    "display(ui)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iat460",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
